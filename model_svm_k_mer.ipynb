{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier with $k$-mer Encoding\n",
    "\n",
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# SADR: importing the confusion matrix functionality.\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (2560, 459)\n",
      "X_test: (800, 459)\n",
      "X_val: (640, 459)\n"
     ]
    }
   ],
   "source": [
    "# SADR: path to the dataset.\n",
    "dataset_path = os.path.join(\"preprocessed_datasets\", \"dataset_k_mer.pkl\")\n",
    "\n",
    "# SADR: loading training data.\n",
    "with open(dataset_path, \"rb\") as f:\n",
    "    dataset_k_mer = pickle.load(f)\n",
    "\n",
    "# SADR: getting the training, validation, and testing data.\n",
    "X_train, y_train = dataset_k_mer[\"X_train\"], dataset_k_mer[\"y_train\"]\n",
    "X_val, y_val = dataset_k_mer[\"X_val\"], dataset_k_mer[\"y_val\"]\n",
    "X_test, y_test = dataset_k_mer[\"X_test\"], dataset_k_mer[\"y_test\"]\n",
    "\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"X_val: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Kernel\n",
    "\n",
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SADR: inhomogenous polynomial kernel bias parameter.\n",
    "coef0 = 1\n",
    "\n",
    "# SADR: degree of the polynomial kernel.\n",
    "degree = np.arange(2, 15)\n",
    "\n",
    "# SADR: cost coefficient.\n",
    "C_vals = np.logspace(-2, 1, 50)\n",
    "\n",
    "# SADR: array to store the f1 scores.\n",
    "f1_scores = np.zeros(shape=(degree.shape[0], C_vals.shape[0]))\n",
    "precision_scores = np.zeros(shape=(degree.shape[0], C_vals.shape[0]))\n",
    "\n",
    "# SADR: grid search for the best degree and C values.\n",
    "for _n_d, _d in enumerate(degree):\n",
    "    for _n_c, _c in enumerate(C_vals):\n",
    "        poly_kernel_svm_clf = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"svm_clf\", SVC(kernel=\"poly\", degree=_d, C=_c, coef0=coef0))\n",
    "        ])\n",
    "        \n",
    "        # SADR: training the model.\n",
    "        poly_kernel_svm_clf.fit(X_train, y_train)\n",
    "\n",
    "        # SADR: evaluating the performance on the validation set.\n",
    "        f1_score_val = f1_score(y_val, poly_kernel_svm_clf.predict(X_val))\n",
    "        f1_scores[_n_d, _n_c] = f1_score_val\n",
    "        precision_score_val = precision_score(y_val, poly_kernel_svm_clf.predict(X_val))\n",
    "        precision_scores[_n_d, _n_c] = precision_score_val\n",
    "        print(f\"degree: {_d}, C: {_c}, precision: {precision_score_val}, f1: {f1_score_val}\")\n",
    "\n",
    "# SADR: determining the best degree and C values.\n",
    "# SADR: precision\n",
    "(degree_opt_idx_pr, C_opt_idx_pr) = np.unravel_index(np.argmax(precision_scores), precision_scores.shape)\n",
    "degree_opt_pr, C_opt_pr = degree[degree_opt_idx_pr], C_vals[C_opt_idx_pr]\n",
    "print(f\"degree_opt_pr: {degree_opt_pr}, C_opt_pr: {C_opt_pr}\")\n",
    "\n",
    "# SADR: f1\n",
    "(degree_opt_idx_f1, C_opt_idx_f1) = np.unravel_index(np.argmax(f1_scores), f1_scores.shape)\n",
    "degree_opt_f1, C_opt_f1 = degree[degree_opt_idx_f1], C_vals[C_opt_idx_f1]\n",
    "print(f\"degree_opt_pr: {degree_opt_f1}, C_opt_f1: {C_opt_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9825\n",
      "precision: 0.9761904761904762\n",
      "recall: 0.9903381642512077\n",
      "f1_score: 0.9832134292565947\n",
      "confusion_matrix: [[376  10]\n",
      " [  4 410]]\n"
     ]
    }
   ],
   "source": [
    "# SADR: optimal hyperparameter values.\n",
    "# Precision and F1 scores yield the same optimal hyperparameters for this case.\n",
    "coef0 = 1\n",
    "degree_opt, C_opt = 3, 7.543120063354615\n",
    "\n",
    "X_train_all = np.concatenate((X_train, X_val), axis=0)\n",
    "y_train_all = np.concatenate((y_train, y_val), axis=0)\n",
    "\n",
    "# SADR: training the model on the entire training set.\n",
    "poly_kernel_svm_clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm_clf\", SVC(kernel=\"poly\", degree=degree_opt, C=C_opt, coef0=coef0))\n",
    "])\n",
    "poly_kernel_svm_clf.fit(X_train_all, y_train_all)\n",
    "y_pred = poly_kernel_svm_clf.predict(X_test)\n",
    "\n",
    "# SADR: computing the performance metrics on the test set.\n",
    "print(f\"accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"f1_score: {f1_score(y_test, y_pred)}\")\n",
    "\n",
    "# SADR: printing the confusion matrix.\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"confusion_matrix: {cm}\")\n",
    "\n",
    "# SADR: saving the confusion matrix.\n",
    "cm_path = os.path.join(\"results\", \"k_mer\", \"svm_poly_kernel_cm.npy\")\n",
    "np.save(cm_path, cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussial RBF Kernel\n",
    "\n",
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SADR: cost parameter.\n",
    "C_vals = np.logspace(-2, 1, 10)\n",
    "\n",
    "# SADR: scaling parameter.\n",
    "gamma_vals = np.logspace(-1, 1, 20)\n",
    "\n",
    "# SADR: array to store the f1 scores.                                   \n",
    "f1_scores = np.zeros(shape=(gamma_vals.shape[0], C_vals.shape[0]))\n",
    "precision_scores = np.zeros(shape=(gamma_vals.shape[0], C_vals.shape[0]))\n",
    "\n",
    "# SADR: grid search for the best degree and C values.\n",
    "for _n_gamma, _gamma in enumerate(gamma_vals):\n",
    "    for _n_c, _c in enumerate(C_vals):\n",
    "        gaussian_rbf_svm_clf = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"svm_clf\", SVC(kernel=\"rbf\", gamma=_gamma, C=_c))\n",
    "        ])\n",
    "        \n",
    "        # SADR: training the model.\n",
    "        gaussian_rbf_svm_clf.fit(X_train, y_train)\n",
    "\n",
    "        # SADR: evaluating the performance on the validation set.\n",
    "        f1_score_val = f1_score(y_val, gaussian_rbf_svm_clf.predict(X_val))\n",
    "        f1_scores[_n_gamma, _n_c] = f1_score_val\n",
    "\n",
    "        precision_score_val = precision_score(y_val, gaussian_rbf_svm_clf.predict(X_val))\n",
    "        precision_scores[_n_gamma, _n_c] = precision_score_val\n",
    "        print(f\"gamma: {_gamma}, C: {_c}, precision: {precision_score_val}, f1: {f1_score_val}\")\n",
    "\n",
    "# SADR: precision\n",
    "(gamma_opt_idx_pr, C_opt_idx_pr) = np.unravel_index(np.argmax(precision_scores), precision_scores.shape)\n",
    "gamma_opt_pr, C_opt_pr = gamma_vals[gamma_opt_idx_pr], C_vals[C_opt_idx_pr]\n",
    "print(f\"gamma_opt_pr: {gamma_opt_pr}, C_opt_pr: {C_opt_pr}\")\n",
    "\n",
    "# SADR: f1\n",
    "(gamma_opt_idx_f1, C_opt_idx_f1) = np.unravel_index(np.argmax(f1_scores), f1_scores.shape)\n",
    "gamma_opt_f1, C_opt_f1 = gamma_vals[gamma_opt_idx_f1], C_vals[C_opt_idx_f1]\n",
    "print(f\"gamma_opt_f1: {gamma_opt_f1}, C_opt_f1: {C_opt_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.925\n",
      "precision: 0.988950276243094\n",
      "recall: 0.8647342995169082\n",
      "f1_score: 0.9226804123711341\n",
      "confusion_matrix: [[382   4]\n",
      " [ 56 358]]\n"
     ]
    }
   ],
   "source": [
    "# SADR: optimal hyperparameter values.\n",
    "# Precision\n",
    "# gamma_opt, C_opt = 0.1, 0.01\n",
    "# F1\n",
    "gamma_opt, C_opt = 0.1, 2.1544\n",
    "\n",
    "X_train_all = np.concatenate((X_train, X_val), axis=0)\n",
    "y_train_all = np.concatenate((y_train, y_val), axis=0)\n",
    "\n",
    "# SADR: training the model on the entire training set.\n",
    "gaussian_rbf_svm_clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm_clf\", SVC(kernel=\"rbf\", gamma=gamma_opt, C=C_opt))\n",
    "])\n",
    "gaussian_rbf_svm_clf.fit(X_train_all, y_train_all)\n",
    "y_pred = gaussian_rbf_svm_clf.predict(X_test)\n",
    "\n",
    "# SADR: computing the performance metrics on the test set.\n",
    "print(f\"accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"f1_score: {f1_score(y_test, y_pred)}\")\n",
    "\n",
    "# SADR: printing the confusion matrix.\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"confusion_matrix: {cm}\")\n",
    "\n",
    "# SADR: saving the confusion matrix.\n",
    "cm_path = os.path.join(\"results\", \"k_mer\", \"svm_rbf_kernel_cm.npy\")\n",
    "np.save(cm_path, cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
